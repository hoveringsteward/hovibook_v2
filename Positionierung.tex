% !TEX root = diplomarbeit.tex
\chapter{Positionierung}
\renewcommand{\kapitelautor}{Autor: Christina Bornberg, Lucas Ullrich}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Allgemeine technische Planung}

    \subsubsection{Allgemein}
    Um eine Positionsbestimmung durchzuführen, benötigt man ein Trackingsystem. 
    Es gibt mehrere Verfahren, um ein Objekt zu tracken: \cite{PositionAllg}
    \begin{itemize}
    \item Mechanische Systeme, umgesetzt mit einer physikalischen Verbindung
    \item Elektromagnetische Tracking, umgesetzt mit elektromagnetischen Wellen
    \item Akustisches Tracking, umgesetzt mit akustischen Wellen
    \item Optisches Tracking, umgesetzt mit elektromagnetischen Wellen
    \item Inertial Tracking, umgesetzt mit Beschleunigungsmessern und Gyroskopen
    \item hybride Ansätze, umgesetzt mit Kombinationen, die mehrere Systeme vereinen
    \end{itemize}   
    Auf die elektromagnetischen, optischen und akustischen Verfahren werden in späteren Abschnitten genauer behandelt.

    \subsubsection{Anwendung} 
    Indoor Positionierungssysteme werden derzeit vor allem zur Objekterkennung, im Umweltmonitoring, über das Detektieren von Bränden in Gebäuden, bis hin zum Einsatz in der Logistik, verwendet. Da es sehr viele unterschiedliche Anwendungsgebiete gibt, werden unterschiedliche Methoden verwendet. \cite{posAnwendung}

    \subsubsection{Eigenschaften der Positionsbestimmung}

    Ein Positionierungssystem kann verschiedene Arten von Informationsdaten aufweisen. \cite{pos_eigenschaften}

    \subsection*{Physische und symbolische Positionierung}
    Die physische Positionierung ist eine exakte Position, die zum Beispiel in einem Koordination, meist in 2-D oder 3-D Karten, bestimmt wird. Längen- und Breitengrade spielen dabei eine wichtige Rolle.\\
    Symbolische Positionierung ist die abstrakte beschreibung eines Ortes, sie wird sprachlich beschrieben, beispielsweise Küche, Garten, Dachboden.\\
    Eine physikalische Position kann auch symbolisch Beschrieben werden.
    
    \subsection*{Relative und absolute Positionierung Lucas}
    \textbf{Absolute Positionsmessung}\\
    Hier wird die Position von einem gleichbleibenden Punkt aus gemessen. Dabei ist ein konstanter Referenzpunkt wichtig.
    Verändert sich dieser oder kann die Distanz nicht genau gemessen werden ist die Messung unbrauchbar.

    Für eine absolute Positionsmessung bieten sich diverse Triangulationsverfahren an,
    diese sind ausgesprochen rechenaufwändig und benötigen meist eine sehr genaue Laufzeitmessung.
    Für die Triangulation können die unterschiedlichsten Signale verwendet werden, am gängigsten sind jedoch jene die mit elektromagnetischen Wellen arbeiten,
    \zB WLAN, Bluetooth. Dies bedeutet, dass sich die Signale mit Lichtgeschwindigkeit ausbreiten.

    Bei einer Messung derart schneller Signale muss ein hoher Aufwand betrieben werden um eine Messgenauigkeit von einigen cm zu erzielen.
    Eine weitere Herausforderung sind Mauern \bzw Hindernisse. Hier muss ständig berücksichtigt werden wo ein Objekt steht und ob der geplante Weg überhaupt frei ist.

    \subsection*{Relative Positionsmessung}
    Hier wird die Position von einem wechselnden Punkt aus gemessen. Um hier eine Positionierung im Raum ermöglichen zu können,
    ist es erforderlich immer zu einem bestimmten Punkt zu messen. Ein Wechsel dieses Punktes ist jedoch möglich,
    deshalb muss auch die Position der Punkte im Raum bekannt sein. Ist die Zielposition im Raum bekannt kann zu dieser hin navigiert werden.
    Auch hier muss wie bei einer absoluten Positionsmessung auf Hindernisse geachtet werden.

    Die zweite Alternative ist, dass eine bestimmte Route bekannt ist und sich das zu positionierende Objekt nur in einem bestimmten Bereich um diese Route bewegt.
    Wird bei der Positionierung der Route bereits auf Hindernisse geachtet müssen diese im Anschluss nicht mehr zwingend beachtet werden.
    \end{itemize}

    \subsection*{Selbst- und fernortende Lokalisierungstechniken}
    Lokalisierungstechniken können weiter als selbstortend oder fernortend (engl. self­positioning/remote­positioning) klassifiziert werden. Beim optischen Tracking werden die beiden Varianten Inside-out und Outside-in genannt.\\
    Beim selbstortenden Positionierungssystem bekommt der mobile, bewegliche Empfänger die Daten von verschiedenen Sendern, die sich auf bekannten Positionen befinden. Die Lokalisation des Empfängers wird durch die gemessenen Signale ermittelt. Das Objekt kann sich selbst orten, es ist kein Netzwerk notwendig.\\
    Ein fernortendes Positionierungssystem besteht aus einem mobilen, beweglichen Sender und stationären, unbeweglichen Empfängern. Die Messdaten aller Empfänger werden gesammelt und die Position des Senders wird in der Zentrale berechnet. Hier ist ein Netzwerk notwendig, sämtliche Berechnungen werden durch eine zentrale Instanz ausgeführt.
    % BILD %

    \subsection*{Genauigkeit}
    Die Genauigkeit gibt an, wie sehr sich gemessene und tatsächliche Position unterscheiden.

    \subsection*{Skalierung}
    Hierbei gibt es mehrere Faktoren, beispielsweise die Anzahl der zu trackenden Objekte, die Reichweite und die benötigte Zeit.

    \subsection*{Kosten}
    Hier gibt es Kosten im Bereich der Anschaffung des Systems und Kosten während des Betriebs.

    \subsection*{Limitierung}
    Unter Limitierung fallen Einschränkungen und Störfaktoren. Manche Systeme haben besondere Ansprüche an ihre Umgebung.


    \subsubsection{Elektromagnetische Verfahren}

    Verfahren zur Positionsbestimmung mittels Signal: \cite{pos_signal_2} \cite{pos_signal_4}
    
    \subsection*{Lateration}
    Bei der Lateration wird die Position mit Hilfe der Entfernungsmessung bestimmt.
    Techniken der Lateration sind TOA (time of arrival) und TDOA (time difference of arrival).\\
    Bei \textbf{TOA} werden Signale in Laufzeit gemessen. Durch die Zeitdifferenz zwischen Sender und Empfänger, kann die Entfernung mithilfe der Information, wie schnell sich das Signal fortbewegt, errechnet werden. Da sich elektromagnetische Wellen in Lichtgeschwindigkeit ausbreiten, ist die zu messende Laufzeit sehr gering. Ultraschallsignale bewegen sich vergleichsweise langsam, dies vereinfacht die Zeitmessung. 
    Um schlussendlich die Position zu bestimmen, werden 3 Basisstationen benötigt, die jeweils eine Entfernungsmessung zum mobilen Objekt durchführen. Durch die 3 Entfernungen kann mittels Trilateration die Position berechnet werden.
    \\ % BILD %
    \textbf{TDOA} basiert auf der Laufzeitdifferenzmessung. 
    Die mobile Sation sendet einen Zeitstempel an drei Basisstationen. Durch die Differenz der Laufzeiten, kann die Position ebenfalls mittels Trilateration bestimmt werden.
    \\ % BILD %
    \subsection*{Angulation}
    Bei der Angulation wird die Position durch die Bestimmung von Winkeln ermittelt. \\
    \textbf{AOA} (Angel of Arrival) wird mittels Berechnung des Einfallswinkels auf ein Antennenarray umgesetzt. Bei dieser Technik werden mindestens 2 Basisstationen benötigt. Mit den Einfallswinkeln der empfangenen Signale kann die Position durch Triangulation festgestellt werden. Die Winkelbeziehungen eines Dreiecks werden dafür verwendet.
    Bei dieser Technik muss keine Synchronisation durchgeführt werden. Der Nachteil ist die benötigte komplexe Hardware. 
    \\ % BILD %
    \subsection*{Scene Analysis}
    Bei der Szenenanalyse werden Umgebungsparameter erfasst und ausgewertet.\\
    Für die Technik \textbf{Fingerprint} werden Signalstärken gemessen und als Fingerprint in einer Datenbank abgespeichert. Die Position wird dann durch den Vergleich von Fingerprints mit der Signalstärke, die bei der aktuellen Position gemessen wird, herausgefunden.
    \subsection*{Proximity}
    Für das Verfahren Proximity wird die physische Nähe genutzt.
    Hier gibt es die Technik COO (cell of origin). \\
    Bei \textbf{COO} gibt es Basisstationen, mit bekannter Position. Die mobile Station verbindet sich mit der nächstgelegenen Basisistation. Wenn die mobile Station von mehreren Basisstationen erkannt wird, wird die Signalstärke beachtet. Diese Methode ist sehr ungenau.
    \\ % BILD %

    \subsubsection{Elektromagnetische Technologien}
    \subsection*{GPS (Global Positioning System)}
    GPS ist ein satellitengestützte Navigationssystem, das Ende der 1980er-Jahre zur globalen Positionsbestimmung entwickelt wurde. Die Nachteile des Systems sind der schlechte Empfang der Satellitensignale für indoor- Anwendungen. 
    \subsection*{RFID (radio-frequency identification)}
    RFID bezeichnet eine Technologie für Sender-Empfänger-Systeme zum automatischen und berührungslosen Identifizieren und Lokalisieren von Objekten mit Radiowellen. Ein RFID-System besteht aus einem Transponder, der sich am oder im Objekt befindet und einen kennzeichnenden Code enthält, sowie einem Lesegerät zum Auslesen dieser Kennung. 
    \subsection*{WPS (WLAN Positioning System)}   
    WPS ist ein indoor Positionierungssystem, das auf WLAN basiert. Durch sogenannte  Access Points (de. drahtloser Zugangspunkt), wird die Entfernung zu Endgeräten bestimmt. Durch drei Accesspoints kann mittels Dreiecksmethode, die Position des Endgeräts ermittelt werden.

    \subsubsection{Akustische Verfahren}
    \subsection*{Laufzeitdifferenzverfahren}
    Das Laufzeitdifferenzverfahren wird auch Transit Time oder Time of Flight Verfahren genannt. \cite{akustischeverfahren}
    \subsubsection{Akustische Technologien}
    \subsection*{Ultraschall}
    Ein Ultraschallsensor ist Sender und Empfänger in einem. Das System basiert auf der Zeitdifferenzmessung. Er sendet ein Signal, dieses wird reflektiert und anschließend empfängt der Sensor sein eigenes Echo.
    Durch die Information, mit welcher Geschwindigkeit sich elektromagnetische sowie akustische Wellen ausbreiten, ist es möglich Entfernungen zu messen. Die Zeit, die ein Signal zum zu messenden Objekt und wieder zurück braucht, nennt man Laufzeit.


    \subsubsection{Optische Verfahren}
    Maschinelles Sehen (machine vision) beschreibt die Fähigkeit eines Computers zu sehen. 
    Für einen Menschen ist es einfach, Objekte auf einem Bild zu erkennen, für Computer besteht ein Bild jedoch aus Daten, die die Graustufe beziehungsweise Farbe jedes einzelnen Pixels angeben, was die Möglichkeit des "Bildverstehens" erschwert.
    Die Auswertung erfolgt mathematisch, weswegen die Stärken von maschinellem Sehen im Bereich der Bestimmung von Farben und Graustufen, sowie der Entfernungsmessung liegen. Weiters können Maschinen, im Gegensatz zum menschlichen Auge, Infrarotlicht, Ultraviolettes Licht und Röngtenstrahlen wahrnehmen. \cite{machinevision} \cite{machinevision2}

    Es wird zwischen Objekt Erkennung (detection) und Verfolgung (tracking) unterschieden. Erkennung bezieht sich auf ein einzelnes Objekt, dass in einem Bild erkannt wird. Bei der Verfolgung werden ein oder mehrere Objekte über eine Sequenz von Bildern erkannt und somit verfolgt.
    \cite{obj_det_trak}

    \subsection*{Bildverarbeitung} 
    Die Bildverarbeitung besteht aus einer Reihe von Schritten, je nach Anwendung werden dabei manche ausgelassen.
    Der Beginn besteht aus der Bildvorverarbeitung, bei der das Bild optisch verbessert wird. Daraufhin folgt die Bildanalyse, die aus den Schritten Segmentierung, in der das Bild in Bereiche aufgeteilt wird, Merkmalsextraktion und Klassifizierung, bei der das Bild Klassen zuge besteht. \cite{Bildverarbeitung} \cite{Bildverarbeitung2}

    \subsection*{Segmentierung}
    Beim Segmentieren teilt man ein Bild in Segmente mit gleichen Merkmalen auf.

    \subsection*{Pixelorienterte Segmentierung} 
    Pixelorientierte Segmentierung wird auch Punktorientierte Segmentierung genannt. Sie basiert auf den lokalen Pixelinformationen, in Abhängigkeit der Grauwerte \cite{Seg_punkt}
    \textbf{Treshholding}\\ 
    Beim Treshholding, auch Schwellenwertverfahren genannt, werden Bildpunkte verschiedenen Gruppen zugeordnet. Da es eine histogrammbasierte Segmentierung wird das zu segmentierende Bild binärisiert, das bedeutet, dass jedes Pixel entweder schwarz oder weiß eingefärbt wird. Dies wird durch den Vergleich des Grauwerts oder einem anderen eindimensionalen Merkmal mit einem Schwellwert, erreicht. Der Grauwert bezieht sich nur auf die Helligkeit der Pixel, Informationen zur Farbe werden dabei ignoriert. Da dieses Verfahren bei jedem einzelne Pixel unabhängig angewendet wird, gehört es zur Pixelorientierten Segmentierung. Diese Technik benötigt wenig Rechenleistung, weshalb es in Echtzeitsystemen angewendet werden kann.

    \subsection*{Modellbasierte Segmentierung} 
    Modelle, bestehend aus Pixelgruppen, werden auf Instanzen geprüft. Einfache Modelle werden mittels Template Matching oder der Hough-Transformation analysiert. \cite{Seg_modell}
    \textbf{Templatematching}\\
    Um Objekte in Bildern zu finden, müssen Information zu Struktur, Form oder Farbe vorliegen. Tempaltes, in denen diese Informationen enthalten sind, werden mit dem Bild verglichen. Anschließend wird die Region im Bild gesucht, die die größte Ähnlichkeit aufweist.
    \textbf{Hough-Transformation}\\
    Durch die Hough-Transformation können anhand der Anzahl der Pixel, die von der gesuchten Form überdeckt werden, geometrische Objekte wie beispielsweise Kreise erkannt werden. Dieses Verfahren ist sehr robust, da es auch auf verrauschten Bildern unvolsltändige oder teils verdeckte Objekte erkennt.

    \subsection*{Regionenorientierte Segmentierung} 
    Hier werden benachbarte Pixel auf Gleichheit zum Startpixel geprüft. \cite{Seg_region}
    \textbf{Region Growing}\\ 
    Bei diesem Verfahren geht man von einem Startpixel, beziehungsweise Seed-Point aus, dieses kann entweder vom Menschen selbst oder vom Computer gewählt werden. Dieses wird mit benachbarten Pixel auf ähnliche Eigenschaften verglichen. Wenn diese Pixel genügend Ähnlichkeit aufweisen, werden sie zu einer sogenannten Region hinzugefügt, andernfalls wird das jeweilige Pixel ignoriert. Die Technologie kann in verrauschten Bildern angewendet werden.

    \subsection*{Texturorientierte Segmentierung} 
    Da sich Objekte oft durch eine einheitliche Struktur auszeichnen, versucht dieses Verfahren als Homogenitätskriterium zu verwenden. Texturorientierte Segmentierung wird meist zur unterstützung anderer Methoden verwendet. \cite{Seg_textur}
    \textbf{Co-Occurrence-Matrizen}
    Um eine Texturanalyse durchzuführen, kann die Cooccurrence-Matrix, auch Grauwertübergangsmatrix genannt, verwendet werden. \cite{seg_coocc}
    Bei dieser Matrix werden die Grauwertverhältnisse der Umgebung eines Pixels beschrieben.

    \subsection*{Merkmalsextraktion}
    Bei diesem Schritt sollen Merkmale wie Kanten und Ecken erkannt werden.
    \textbf{Kantendetektion}\\
    Im menschlichen Sehen, haben Kanten eine wichtige Bedeutung. Durch sie kann ein Bild beinahe vollständig nachgebildet werden. Es gibt einige Verfahren um diese Erkennung durchzuführen.
    \textbf{Sobel Operator} Faltung des Bildes mit Hilfe einer Sobel-Matrix und anschließende Approximation der ersten Ableitung des Bildes
    \textbf{Laplace-Filter}
    \textbf{Canny Algorithmus} Zur Glättung, Einsatz eines zweidimensionalen Gaußfilters und Einsatz von gerichteten Ableitungsoperatoren. Nach der Ausdünnung der Linien, Anwendung einer Hysterese zur Erkennung ob es sich um eine Kante oder um ein Rauschen handelt.
    \textbf{Sombrerofilter} Der Sombrerofilter wird auch Laplace of Gaussian Operator und Marr-Hildreth-Operator genannt.

    \textbf{Eckendetektion}\\
    Ecken sind Punkte, in denen zwei Kanten enden, weswegen sie ebenfalls ein wichtiges Merkmal in einem Bild darstellen. Hierfür gibt es ebenfalls mehrere Verfahren.
    \textbf{Moravec´s Corner Detector} Betrachtung eines kleinen lokalen Bildfensters und Messung der Intensitätsunterschiede beim Verschieben des Fensters. Erkennung von Kanten und Ecken
    \textbf{Harris Corner Detector} Betrachtung eines lokalen Bildfensters durch Verschiebung in 4 Richtungen durch die Taylor Entwicklung


    \subsection*{Klassifikation} 
    Klassifizieren ist das Zusammenfassen von Objekten zu einer Gruppe/Klasse/Kategorie. Hier gibt es beispielsweise die Klassifikation nach Farbe, Kontrast, Segmentgröße, Form oder Textur. Durch die Klassifikation soll das Erkennen von Zusammenhängen verbessert werden. Ein Objekt, bei dem alle relevanten Eigenschaften vorliegen, kann korrekt klassifiziert werden. Da in den meisten Fällen nicht alle Informationen vorliegen, wird eine Klassifizierung anhand eines Merkmalvektors, der aus einer Reihe passender Merkmale entsteht, durchgeführt. \cite{Bildverarbeitung}
   
    \subsection*{Verfolgen von Objekten}
    \textbf{Kalman-Filter}\\
    Kalman-Filter: Ist ein stochastischer Zustandsschätzer mit iterativer Struktur, der in Echtzeitsystemen angewendet wird unter der Annahme von normalverteilten Vorhersagen und Messungen und Vorhersage von Fehlern.

    \textbf{Optical-Flow}\\
    Optical Flow: Oberflächen erhalten eine Geschwindigkeit und eine Richtung, wobei die Bewegung von einer 3 D Szene in die 2 D Bildebene unter Berechnung eines Bewegungsvektors, der die Bewegung in Bildkoordinaten ausdrückt.

    Optical Flow:
    Dazu werden Bilder von einer Kamera an der Frontseite des Multicopters aufgenommen. Ein mitfliegender Microcontroller verarbeitet dann die Bilder mit Hilfe einer entwickelten Software. Durch einen Mustervergleich wird die richtige Situation eingeschätzt. Das Konzept funktionierte bei Translationen-Bewegung. Drehungen und größere Winkel führten jedoch zu Fehlinterpretationen. Zur Berechnung des optischen Flusses (optical flow) werden Algorithmen von Shi-Tomasi und Lucas-Kanade verwendet. Die Shi-Tomasi Algorithmen benötigen markante Punkte in Bildern, um diese wieder erkennen zu können. Auch die Lucas-Kanade-Methode verwendet die Methode der Eckenerkennung, Punkte und Ecken müssen wiedererkannt werden. \cite{opticalflow}

    \subsubsection{Optische Trackingsysteme}

    Die Lokalisierung von sich bewegenden Objekten und Bewegungserfassung

    \subsection*{Pixy CMUcam5}
    Die Pixy CMUcam5 ist ein optisches Trackingsystem. Das Kameramodul ist in der Lage, Objekte in 7 verschiedenen Farben zu scannen, diese zu speichern und wiederzuerkennen. Daten über die Höhe und die Breite, sowie die x- und y-Position des getrackten Objektes innerhalb des Frames werden ausgegeben. Bei sogenannten Colorcodes, die sich aus zwei oder mehrfarbigen Objekten ergeben, kann die Rotation des Objektes ebenfalls ermittelt werden.

    \textbf{CMVision}
    CMVision, Color Machine Vision, ist ähnlich dem Algorithmus der Pixy
    % https://books.google.at/books?id=QHUlp1tI-JwC&pg=PT480&lpg=PT480&dq=cmvision+cmucam&source=bl&ots=xn9xZCsBk1&sig=v3GwsxR9w4SRIRX9p7uzolQWqdc&hl=de&sa=X&ved=0ahUKEwjlidqal7HLAhUGKXIKHdSuBSsQ6AEIQjAF#v=snippet&q=cmucam&f=false

    \cite{Pixy}
    \cite{Pixy_Verfahren}
    \cite{Pixy_Verfahren2}

    \subsection*{Vicon}
    Vicon ist ein System, das mit dem Tracking-Verfahren Motion Capture (Bewegungs-Erfassung) arbeitet. 
    Mehrere Kameras werden in einem Raum verteilt. Jede Kamera besitzt einen Infrarotfilter und Infrarot-LEDs. Die Lampen senden infrarotes Licht aus, dieses wird an Markern, die sich auf dem zu trackenden Objekt befinden, reflektiert. Mithilfe einer Software kann dadurch eine dreidimensionale Karte erstellt werden.
    \cite{Vicon}

  \subsection{Konzepte}
  Die verschiedenen Positionierungsarten wurden verwendet, um Konzepte für die Navigation zu entwickeln.

    \subsubsection{Aufgabenstellung}
    Damit der Hexacopter autonom durch den Raum navigieren kann, benötigt er ein Positionierungssystem.

    \subsubsection{Funkbasiertes Tracking}

      \subsection*{Tracking mittels Time of Arival}

      Mithilfe der Laufzeitmessung können Objekte, die mit einem Empfänger ausgestattet sind, geortet werden. Dafür wird die Zeit die ein Signal vom Sender zum Empfänger benötigt gemessen. Das Signal ist eine elektromagnetische Welle, die sich im Vakuum in Lichtgeschwindigkeit ausbreitet. Die gemessene Laufzeit wird mit der Lichtgeschwindigkeit multipliziert, damit kann die Entfernung berechnet werden. 

      Bei diesem Konzept, soll durch die benützung sogenannter Pseudolites (Gefälschte Sateliten) eine Art lokales GPS erschaffen werden.

      Das System besteht aus 3 Sendern, die signale Schicken und einem Empfänger, der sich im Hexacopter befindet.
      Durch das Senden eines Signals von jedem Pseudolite zum Empfänger, können 3 Distanzen berechnet werden.
      Aus diesen 3 Distanzen und der bekannten Koordinaten der Pseudolites, wird die augenblickliche Position mittels Trilateration des Hexacopters berechnet.

%\[
%      Distanz 1 = (x1 - x)^2 + (y1 - y)^2 + (z1 - z)^2
%      Distanz 2 = (x2 - x)^2 + (y2 - y)^2 + (z2 - z)^2
%      Distanz 3 = (x3 - x)^2 + (y3 - y)^2 + (z3 - z)^2
%\]

      Distanz ... ist die durchgeführte Messung\\
      x1, y1, ... z2, z3 ... sind die staatischen Koordinaten von den Pseudolites \\
      x, y, z ... werden durch die Lösung dieses quadratischen Gleichungssystems ermittelt \\
      
      Beim lösen der Gleichung erhält man 2 Schnittpunken. Dies ergibt sich aus der logischen Schlussfolgerung, dass die Oberflächen 3er verschmolzener Kugeln 2 Schnittpunkte haben.
      Wenn die Pseudoliten am Boden anbringt, liegt eine der beiden Lösungen oberhalb und die 2. Lösung unterhalb des Bodens, womit man einfacherweise, die Lösung mit der negativen Z-Koordinate ausschließen kann.

    \subsubsection{Optisches Tracking}
    % Aufgrund der Komplexität einer signalbasierten

  \subsection*{Kamerasystem im Raum}

  Beim optischen Tracking mit Markern wird mit Kameras gearbeitet, welche aktive (also ein Signal emittierende) oder passive Marker an den zu erfassenden Personen oder Gegenständen verfolgen. 

  Für ein fernortendes Positionierungssystem, werden Kameras in einem Raum verteilt. 
  Sowohl Tische und Kreuzungen als auch der Hexacopter sind mit Markern versehen. Die einzelnen Komponenten werden vom Kamerasystem erfasst und anschließend wird eine Karte erstellt. Diese Karte besitzt, wie ein Koordinatensystem Längen und Breitengrade.

  Der Hexacopter wählt seine Route, die er mittels Position der Kreuzugen und Tische berechnet.

  Durch das Trackingsystem kann die Position des Hexacopters getrackt werden. Somit wird kontrolliert, ob er sich auf der richtigen Route befindet.

  Anhand der Markerbewegungen in den einzelnen Kamerabildern kann mittels Triangulation die Position der Marker in 3D berechnet werden.

  \subsection*{Linien}
  Bei einem selbstortenden Positionierungssystem sind Sensoren auf dem sich bewegenden Objekt angebracht.
  Der Hexacopter trackt eine Linie, die Kamera ist am Hexacopter befestigt
  Zunächst wurde ein Konzept mit Linien erstellt. Der Hexacopter folgt einer einfarbigen Linie, bis er zu einer Kreuzung kommt, nun ist seine Aufgabe, die nächste Linie zu finden, um seinen Weg zum Ziel zu finden.  

  Vorteile: Der Hexacopter kann die Linie nur schwer verlieren
  Nachteile: Das verwendete Kamerasystem ist nicht in der Lage eine Linie zu tracken.


  \subsection*{Farbcode pro Wegabschnitt}
  Durch die Verwendung der Pixy CMUCam5 ergibt sich die Möglichkeit, Farbobjekte, die eine oder mehrere Farben haben, zu scannen.

  Bei diesem Konzept bekommt der Mikrocontroller Informationen zu den Farbobjekten pro Wegabschnitt. Vom Start bis zur ersten Kreuzung verwendet er eine Farbinformation, die aus einem Colorcode besteht. Jedes Farbobjekt auf diesem Weg, hat die selben 2 Farben. Durch diese Technik hat der Administrator des Systems weniger Aufwand.

  Version 1: 1 ColorCode pro Wegabschnitt

  Vorteile:
  - (kein Problem, wenn ein Farbobjekt nicht mitgetrackt wird)

  Nachteile:
  - die Korrektur der Rotation ist komplizierter, da zuerst über das Koordinatensystem der Kamera herausgefunden werden muss, welches Farbobjekt am nächesten zu y = 0 ist. 
  - Weiß nicht, ob das Nächste wirklich das Nächste ist oder ein Fehler

  \subsection*{Farbcodes variieren}
  Das gewählte System wird ebenfalls mittels 2-farbiger Codes umgesetzt.

  Erklärung: Jedes Farbobjekt hat einen ColorCode

  Vorteile:
  keine großartigen Kosten neben Copter und Server
  Rechnung am Hexacopter
  - relative Position kann besser bestimmt werden
  - kennt das Ende des Weges und muss daher nicht herausfinden, wann der Weg zu ende ist und die Landeplattform vor ihm ist

  Nachteile:
  - (Probleme, sollte ein Farbobjekt nicht erkannt werden)
  - Mehr Aufwand bezüglich auflegen der Farbobjekte -> man muss eine Reihenfolge beachten. Dadurch müssen auch mehrere Daten vom Server geschickt werden. => die Farbinformation ist länger, da jedes einzelne Objekt eingetragen werden muss. 



  \subsection*{Tracking mittels Infrarot}
  Um das System auch ohne entsprechende Lichtverhältnisse durchführen zu können, besteht die Möglichkeit einen Infrarotfilter an der Pixycam anzubringen und die Wegpunkte mittels Infrarotlampen zu makieren. 

  Vorteile:
  System funktioniert ebenfalls im Dunkeln.
  Nachteile: 
  Jeder Tisch benötigt einen Stromanschluss.
  Die Wartung ist aufwändiger.
  Komplexer für den Administrator - wo ist welcher Infrarotsender (Für den Menschen nicht sofort ersichtlich)


  \subsubsection{Das gewählte Konzept}
  Das gewählte Konzept ist eine hybride Methode zwischen optischen Trackings und einer Laufzeitmessung. 
  Durch die Pixy CMUcam5 werden am Boden liegende Farbcodes getrackt. Diese variieren um die relative Position besser zu bestimmen. Mit der Information, über welchem Farbcode sich der Hexacopter befindet, kann die Position im 2 Dimensionalen Raum herausgefunden werden. Da der Hexacopter fliegt, muss das System 3 Dimensional sein. Die z-Koordinate, beziehungsweise die Höhe, wird deswegen mit einem Ultraschallsensor über eine Laufzeitmessung bestimmt.

  Das System wurde auf die oben erklärten Eigenschaften analysiert:

  \subsection*{Physische und symbolische Positionierung}
  Die Positionierung erfolgt physisch. Durch die Pixy kann die tatsächliche Position ermittelt werden.
  Zum Besseren verständnis, wir die Positionen ebenfalls symbolisch beschrieben. Es werden die Namen Base, für die Küche beziehungsweise den Stützpunkt, Weg für die Route aus Colorcodes und Tisch, für die Landeplattform, auf der der Hexacopter landen soll, verwendet.

  \subsection*{Relative Positionierung}
  Das gewählte System gestaltet sich relativ, da der Hexacopter seine Position relativ zu Farbobjekten bestimmt.

  \subsection*{Selbstortendes Positionierungssystem}
  Das Positionierungssystem ist selbstortend. Die am boden liegenden Farbobjekte werden von der Pixy getrackt und die daraus entstehenden Daten verarbeitet. Der Hexacopter kann ohne externe Einflüsse navigieren und ist somit unabhängig.

  \subsection*{Genauigkeit}
  Da das System mittels optischem Tracking umgesetzt wird, ist die Genauigkeit sehr hoch.
  
  \subsection*{Skalierung}
  Das System ist beliebig Skalierbar, da es auf Farbcodes basiert. Es besteht die Möglichkeit, beliebig viele Farbcodes dem Weg hinzuzufügen oder wieder wegzunehmen. Die Routen sind im Adminbereich hinterlegt und müssen, je nach dem, wie der Administrator die Farbcodes legt, diese auch mitverändern. Im System gibt es aus Testgründen eine Grenze von 20 Farbcodes, diese kann aber einfach verändert werden.

  Die Pixy CMUcam5 ist in der Lage 135 Objekte pro Frame zu tracken. Unser System ist selbstortend, dewegen interessiert sich der Hexacopter nur für ein Objekt pro Frame. \cite{PIXY_Porting_Examplecode}

  Das System ist, wegen des Ultraschallsensors auf eine Höhe von 3 Metern begrenzt. Im System ist eine Maximalhöhe von 220m über dem Boden und 120m über einem Tisch hinterlegt.

  \subsection*{Kosten}
  Da  die Positionierung auf einer Kamera mit Farbcodes, einem Ultraschallsensor, einem Mikcrocontroller und einem WLAN fähigen Gerät basiert, beschränken sich die Kosten auf wenige Hundert Euro

  \subsection*{Limitierung}
  Die Pixy CMUcam5 muss zuvor gespeicherte Farben wiedererkennen, die Lichtverhältnisse müssen daher optimal sein.  
  Objekte müssen eine Mindestensgröße von 4x1 Pixel in einem Frame ausmachen. Die Pixycam kann Objeke, laut Angaben der Website, über Kilometer tracken, wenn diese groß genug sind. Beispielsweise kann ein Objekt in Ping-Pong Ball Größe aus einer Entfernung von etwa 3 Metern gescannt werden. \cite{Pixy}

  Das System kann sowohl Indoor als auch Outdoor angewendet werden.

  Der verwendete Ultraschallsensor misst die Entfernung mit einer Auflösung von 3mm. Er eignet sich für den Bereich zwischen 2cm und 3m. \cite{Ultrasonic}

 